import os
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel


BASE_MODEL = r"H:\AI-Behavior-Research\models\qwen\qwen2.5-3b"
LORA_PATH  = r"H:\AI-Behavior-Research\lora_output\V4\qwen25_behavior_v4.6"

SYSTEM_PROMPT = (
    "ä½ æ˜¯ä¸€å€‹éµå®ˆäº”å¾‹ã€å†·éœç©©å®šã€èƒ½è‡ªæˆ‘ä¿®æ­£ä¸¦ä¾ç…§ E/I/M æ¨ç†çš„ AIã€‚"
    "ä½ å¯ä»¥è‡ªç„¶å°è©±ï¼Œä½†å§‹çµ‚ä¿æŒæ¸…æ™°ã€å®‰å…¨ã€‚"
)


# ---- å–®è¼ª Qwen æ ¼å¼ ----
def format_qwen_single_turn(user_msg):
    text = (
        "<|im_start|>system\n" + SYSTEM_PROMPT + "\n<|im_end|>\n"
        + f"<|im_start|>user\n{user_msg}\n<|im_end|>\n"
        + "<|im_start|>assistant\n"
    )
    return text


print("ğŸ”„ è¼‰å…¥ tokenizer...")
tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)

print("ğŸ”„ è¼‰å…¥æ¨¡å‹...")
base = AutoModelForCausalLM.from_pretrained(
    BASE_MODEL,
    torch_dtype=torch.bfloat16,
    device_map="auto",
    trust_remote_code=True,
)

print("ğŸ”„ å¥—ç”¨ LoRA...")
model = PeftModel.from_pretrained(base, LORA_PATH)
model.eval()



def ask(msg):
    # å–®è¼ª prompt
    prompt = format_qwen_single_turn(msg)
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)

    with torch.no_grad():
        output = model.generate(
            **inputs,
            max_new_tokens=300,
            do_sample=False,
            temperature=0.7,
            eos_token_id=tokenizer.eos_token_id,
            pad_token_id=tokenizer.eos_token_id,
        )

    decoded = tokenizer.decode(output[0], skip_special_tokens=False)
    try:
        answer = decoded.split("<|im_start|>assistant")[-1]
        answer = answer.split("<|im_end|>")[0].strip()
    except:
        answer = decoded
    return answer


# ---- CLI ----
print("\n====================================")
print(" ğŸ§  V3 Chat Model â€” Ready")
print("====================================")
print("è¼¸å…¥ exit é›¢é–‹\n")

while True:
    msg = input("ä½ ï¼š").strip()
    if msg in ["exit", "quit"]:
        print("å†è¦‹ï¼")
        break

    reply = ask(msg)
    print(f"AIï¼š{reply}\n")
