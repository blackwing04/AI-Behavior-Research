import json
import torch
import csv
from dataclasses import dataclass
from typing import Dict, List
from datetime import datetime
import os

from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    BitsAndBytesConfig,
    TrainingArguments,
    Trainer,
    TrainerCallback,
)
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training


# -------------------------------------------------------
# JSONL é©—è­‰å‡½æ•¸
# -------------------------------------------------------
def validate_jsonl(file_path: str) -> tuple[bool, str]:
    """
    é©—è­‰ JSONL æª”æ¡ˆæ ¼å¼
    
    Returns:
        (is_valid, message): (æ˜¯å¦æœ‰æ•ˆ, è¨Šæ¯)
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    print(f"ğŸ“‹ é©—è­‰ JSONL æª”æ¡ˆ: {file_path}")
    print(f"   ç¸½è¡Œæ•¸: {len(lines)}")
    
    errors = []
    valid_count = 0
    
    for i, line in enumerate(lines, 1):
        if not line.strip():
            continue
        
        try:
            json.loads(line)
            valid_count += 1
        except json.JSONDecodeError as e:
            errors.append(f"ç¬¬ {i} è¡Œ: {str(e)[:100]}")
    
    if errors:
        message = f"\nâŒ æ‰¾åˆ° {len(errors)} å€‹ JSON æ ¼å¼éŒ¯èª¤:\n"
        for err in errors[:10]:
            message += f"   {err}\n"
        if len(errors) > 10:
            message += f"   ... é‚„æœ‰ {len(errors) - 10} å€‹éŒ¯èª¤\n"
        return False, message
    else:
        message = f"âœ… JSONL æ ¼å¼é©—è­‰é€šéï¼({valid_count} ç­†æœ‰æ•ˆè³‡æ–™)"
        return True, message


# -------------------------------------------------------
# è¨“ç·´æŒ‡æ¨™è¨˜éŒ„å™¨
# -------------------------------------------------------
class MetricsLogger:
    """è¨˜éŒ„è¨“ç·´éç¨‹ä¸­çš„æ‰€æœ‰æŒ‡æ¨™"""
    
    def __init__(self, output_dir: str):
        self.output_dir = output_dir
        self.metrics_file = os.path.join(output_dir, "training_metrics.csv")
        self.metrics_list = []
        
        # å»ºç«‹ CSV æ¨™é¡Œ
        os.makedirs(output_dir, exist_ok=True)
        with open(self.metrics_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(['epoch', 'step', 'loss', 'grad_norm', 'learning_rate', 'timestamp'])
    
    def log_metrics(self, epoch: float, step: int, loss: float, grad_norm: float, lr: float):
        """è¨˜éŒ„ä¸€æ¢è¨“ç·´æŒ‡æ¨™"""
        record = {
            'epoch': epoch,
            'step': step,
            'loss': loss,
            'grad_norm': grad_norm,
            'learning_rate': lr,
            'timestamp': datetime.now().isoformat()
        }
        self.metrics_list.append(record)
        
        # å¯¦æ™‚å¯«å…¥ CSV
        with open(self.metrics_file, 'a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([epoch, step, loss, grad_norm, lr, record['timestamp']])
    
    def save_json(self):
        """ä¿å­˜ç‚º JSON æ ¼å¼"""



# -------------------------------------------------------
# è‡ªè¨‚ Callback ä¾†è¨˜éŒ„è¨“ç·´æŒ‡æ¨™
# -------------------------------------------------------
class MetricsCallback(TrainerCallback):
    """åœ¨è¨“ç·´éç¨‹ä¸­è¨˜éŒ„æ¢¯åº¦å’Œæå¤±"""
    
    def __init__(self, metrics_logger: MetricsLogger, model):
        self.metrics_logger = metrics_logger
        self.model = model
    

    def on_log(self, args, state, control, logs=None, **kwargs):
        """åœ¨ Trainer log æ™‚è¨˜éŒ„æŒ‡æ¨™ï¼ˆæ­¤æ™‚ grad_norm è‹¥æœ‰æœƒè¢« logï¼‰"""
        if logs and 'loss' in logs:
            epoch = logs.get('epoch', state.epoch)
            step = state.global_step
            loss = logs.get('loss', 0)
            lr = logs.get('learning_rate', args.learning_rate)
            grad_norm = logs.get('grad_norm', 0.0)  # è‹¥ Trainer æœ‰ log grad_norm
            self.metrics_logger.log_metrics(epoch, step, loss, grad_norm, lr)
            if step % 10 == 0:
                print(f"Step {step} | Loss: {loss:.4f} | GN: {grad_norm:.4f} | Epoch: {epoch:.2f}")
    
    def _compute_grad_norm(self) -> float:
        """è¨ˆç®—æ¨¡å‹æ¢¯åº¦çš„ L2 ç¯„æ•¸"""
        total_norm = 0.0
        for p in self.model.parameters():
            if p.grad is not None:
                total_norm += p.grad.data.norm(2).item() ** 2
        total_norm = total_norm ** 0.5
        return total_norm


# -------------------------------------------------------
# è·¯å¾‘è¨­å®š
# -------------------------------------------------------
# é¸æ“‡è³‡æ–™é›†ä¾†æºï¼š'behavior' æˆ– 'copilot_generic'
DATASET_SOURCE = "behavior"  # â† æ”¹é€™è£¡åˆ‡æ›è³‡æ–™é›†

# å°æ‡‰çš„è¼¸å‡ºè³‡æ–™å¤¾
OUTPUT_MAPPING = {
    "behavior": r"H:\AI-Behavior-Research\lora_output\V4\qwen25_behavior_v4.6",
    "copilot_generic": r"H:\AI-Behavior-Research\lora_output\copilot_generic",
}

BASE_MODEL = r"H:\AI-Behavior-Research\models\qwen\qwen2.5-3b_Test"

# è·¯å¾‘é¸æ“‡
if DATASET_SOURCE == "behavior":
    # V4.4: åŸºæ–¼ V4 çš„æ”¹é€²ç‰ˆæœ¬ï¼Œæ•´åˆæœ¬èƒ½æ–¹ç¨‹å¼è¨“ç·´ï¼ˆåŒæ¨£åœ¨ V4 æ–‡ä»¶å¤¾ï¼‰
    DATASET_PATH = r"H:\AI-Behavior-Research\datasets\behavior\V4\behavior_dataset.jsonl"
elif DATASET_SOURCE == "copilot_generic":
    DATASET_PATH = r"H:\AI-Behavior-Research\datasets\copilot_generic\copilot_generic_dataset.jsonl"

OUTPUT_DIR = OUTPUT_MAPPING[DATASET_SOURCE]

# -------------------------------------------------------
# Qwen2.5 ç³»çµ±æç¤º
# -------------------------------------------------------
SYSTEM_PROMPT = (
    "ä½ æ˜¯ä¸€å€‹éµå®ˆäº”å¾‹ã€å…·å‚™ç©©å®šäººæ ¼ã€æˆç†Ÿæ¨ç†ã€è‡ªæˆ‘ä¿®æ­£ã€"
    "ä¸¦èƒ½ä¾ç…§ E/I/M çµæ§‹é€²è¡Œåˆ¤æ–·çš„ AIã€‚ä¿æŒå†·éœã€æ¸…æ™°ã€ç©©å®šã€‚"
    "åœ¨æ—¥å¸¸å°è©±ä¸­ï¼Œå¯ä»¥è‡ªç„¶ç°¡çŸ­åœ°äº’å‹•ï¼Œä½†ä»ç¶­æŒé‚è¼¯æ¸…æ™°å’Œå®‰å…¨é‚Šç•Œã€‚"
)

def qwen_chat_template(instruction: str, user_input: str, assistant_output: str) -> str:
    user_msg = (instruction.strip() + "\n" + user_input.strip()).strip()
    final_prompt = (
        "<|im_start|>system\n" +
        SYSTEM_PROMPT + "\n<|im_end|>\n"
        "<|im_start|>user\n" +
        user_msg + "\n<|im_end|>\n"
        "<|im_start|>assistant\n" +
        assistant_output.strip() + "\n<|im_end|>\n"
    )
    return final_prompt


# -------------------------------------------------------
# Datasetï¼ˆå« label maskingï¼‰
# -------------------------------------------------------
@dataclass
class SFTDataset:
    data: List[Dict]
    tokenizer: AutoTokenizer

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        ex = self.data[idx]

        prompt = qwen_chat_template(
            ex["instruction"],
            ex["input"],
            ex["output"]
        )

        # --- tokenize ---
        tokenized = self.tokenizer(
            prompt,
            truncation=True,
            max_length=1024,
            padding="max_length",
            return_tensors="pt",
        )

        input_ids = tokenized["input_ids"][0]
        attention_mask = tokenized["attention_mask"][0]

        # --- å»ºç«‹ labels ---
        labels = input_ids.clone()

        # å°‡ <|im_start|>assistant ä¹‹å‰å…¨éƒ¨ mask (-100)
        assistant_token_id = self.tokenizer.encode("<|im_start|>assistant")[0]

        # æ‰¾åˆ° assistant çš„èµ·å§‹ä½ç½®
        positions = (input_ids == assistant_token_id).nonzero(as_tuple=True)[0]

        if len(positions) > 0:
            start = positions[0]
        else:
            start = 0  # è¬ä¸€æ‰¾ä¸åˆ°ï¼Œä¿åº•ä¸è¨“ç·´

        # maskï¼ˆuser/systemï¼‰éƒ¨åˆ†
        labels[:start] = -100

        return {
            "input_ids": input_ids,
            "attention_mask": attention_mask,
            "labels": labels,
        }


# -------------------------------------------------------
# ä¸»ç¨‹å¼
# -------------------------------------------------------
def main():
    print("=" * 60)
    print("ğŸ” ç¬¬ä¸€æ­¥ï¼šé©—è­‰è³‡æ–™é›†")
    print("=" * 60)
    
    # é©—è­‰ JSONL æ ¼å¼
    is_valid, validation_message = validate_jsonl(DATASET_PATH)
    print(validation_message)
    
    if not is_valid:
        print("\nâš ï¸  è³‡æ–™é›†æ ¼å¼æœ‰èª¤ï¼Œè«‹å…ˆä¿®æ­£å¾Œå†è¨“ç·´")
        return
    
    print("\n" + "=" * 60)
    print("ğŸ”„ ç¬¬äºŒæ­¥ï¼šè¼‰å…¥æ¨¡å‹èˆ‡æº–å‚™è¨“ç·´")
    print("=" * 60)
    
    print("ğŸ”„ è¼‰å…¥ tokenizer...")
    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, trust_remote_code=True)

    print("ğŸ”„ è¼‰å…¥æ¨¡å‹ï¼ˆ4bitï¼‰...")
    bnb_config = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_compute_dtype=torch.bfloat16,
        bnb_4bit_quant_type="nf4",
    )

    model = AutoModelForCausalLM.from_pretrained(
        BASE_MODEL,
        device_map="auto",
        quantization_config=bnb_config,
        trust_remote_code=True,
    )

    print("ğŸ”§ æº–å‚™ QLoRA è¨“ç·´...")
    model = prepare_model_for_kbit_training(model)

    lora_config = LoraConfig(
        r=32,
        lora_alpha=16,
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
        lora_dropout=0.05,
        bias="none",
        task_type="CAUSAL_LM",
    )

    model = get_peft_model(model, lora_config)
    model.print_trainable_parameters()

    # --- Dataset ---
    dataset_raw = []
    with open(DATASET_PATH, "r", encoding="utf-8-sig") as f:
        for line in f:
            if not line.strip():
                continue
            dataset_raw.append(json.loads(line))


    train_dataset = SFTDataset(dataset_raw, tokenizer)
    print(f"ğŸ“„ è³‡æ–™é›†è¼‰å…¥å…± {len(train_dataset)} ç­†")

    # --- Training Args ---
    training_args = TrainingArguments(
        output_dir=OUTPUT_DIR,
        per_device_train_batch_size=1,
        gradient_accumulation_steps=8,
        num_train_epochs=1,
        logging_steps=5,
        save_total_limit=2,
        learning_rate=2e-4,
        bf16=True,
        warmup_ratio=0.05,
        optim="paged_adamw_8bit",
        lr_scheduler_type="cosine",
    )

    print("ğŸš€ é–‹å§‹è¨“ç·´ï¼ˆå« Chat æ¨¡æ¿ + Label Maskingï¼‰...")
    
    # åˆå§‹åŒ–æŒ‡æ¨™è¨˜éŒ„å™¨
    metrics_logger = MetricsLogger(OUTPUT_DIR)
    
    # è‡ªè¨‚ Callback ä¾†è¨˜éŒ„è¨“ç·´æŒ‡æ¨™
    metrics_callback = MetricsCallback(metrics_logger, model)
    
    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        tokenizer=tokenizer,
        callbacks=[metrics_callback],
    )

    trainer.train()

    print("ğŸ’¾ å„²å­˜ LoRA...")
    model.save_pretrained(OUTPUT_DIR)
    
    # ä¿å­˜è¨“ç·´æŒ‡æ¨™
    metrics_logger.save_json()
    
    print("ğŸ‰ è¨“ç·´å®Œæˆï¼")
    print(f"ğŸ“Š è¨“ç·´æŒ‡æ¨™å·²ä¿å­˜åˆ°:")
    print(f"   - CSV: {metrics_logger.metrics_file}")
if __name__ == "__main__":
    main()
